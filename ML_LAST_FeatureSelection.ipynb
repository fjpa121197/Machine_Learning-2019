{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from feature_selector import FeatureSelector #credits to Will Koehrsen\n",
    "#his class is on github https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "data_full = pd.read_csv(\"CE802_Ass_2019_Data.csv\")\n",
    "data_class = data_full[\"Class\"]\n",
    "data_full = data_full.drop(columns = [\"Class\"],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelector(data = data_full, labels = data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with the parameters to loop for\n",
    "parameters_features = {'missing_threshold': np.arange(0.35,0.45,0.05),    \n",
    "                       'correlation_threshold': np.arange(0.35,0.75,0.05),\n",
    "                       'task': 'classification',    \n",
    "                       'eval_metric': 'auc', \n",
    "                       'cumulative_importance': np.arange(0.65,1,0.05)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.640707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.744228\tvalid_0's binary_logloss: 0.676268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.764069\tvalid_0's binary_logloss: 0.657408\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.61039\tvalid_0's binary_logloss: 0.672997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's auc: 0.775613\tvalid_0's binary_logloss: 0.586718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.742424\tvalid_0's binary_logloss: 0.602034\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.635467\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.624218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.629764\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.795094\tvalid_0's binary_logloss: 0.557981\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "14 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 14 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.686869\tvalid_0's binary_logloss: 0.632008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.647186\tvalid_0's binary_logloss: 0.658755\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.566739\tvalid_0's binary_logloss: 0.683229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.716089\tvalid_0's binary_logloss: 0.653706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.732684\tvalid_0's binary_logloss: 0.627896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.608888\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.625997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.588057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.601449\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.641414\tvalid_0's binary_logloss: 0.666758\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.629372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.779221\tvalid_0's binary_logloss: 0.561466\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.794372\tvalid_0's binary_logloss: 0.591682\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.578574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.598236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.614719\tvalid_0's binary_logloss: 0.664697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.826118\tvalid_0's binary_logloss: 0.560778\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.769841\tvalid_0's binary_logloss: 0.591189\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.700216\tvalid_0's binary_logloss: 0.656226\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.639317\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.637291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.586289\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.630803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.649351\tvalid_0's binary_logloss: 0.649319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.691558\tvalid_0's binary_logloss: 0.65971\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.664502\tvalid_0's binary_logloss: 0.673604\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.627876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.626984\tvalid_0's binary_logloss: 0.677878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.708874\tvalid_0's binary_logloss: 0.664917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.626263\tvalid_0's binary_logloss: 0.660929\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.565086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.623016\tvalid_0's binary_logloss: 0.665721\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.63925\tvalid_0's binary_logloss: 0.654133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.653095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.67316\tvalid_0's binary_logloss: 0.65099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.57215\tvalid_0's binary_logloss: 0.676025\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.624112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.564214\tvalid_0's binary_logloss: 0.67857\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.62302\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.65052\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.637807\tvalid_0's binary_logloss: 0.678607\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.755411\tvalid_0's binary_logloss: 0.59016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.644076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.810245\tvalid_0's binary_logloss: 0.546826\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.693362\tvalid_0's binary_logloss: 0.64293\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.551099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.630011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.782107\tvalid_0's binary_logloss: 0.602687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.810245\tvalid_0's binary_logloss: 0.539817\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.583697\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.680736\tvalid_0's binary_logloss: 0.672606\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.640619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.577102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.596041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.637925\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.643923\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.611783\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.784632\tvalid_0's binary_logloss: 0.599489\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.622655\tvalid_0's binary_logloss: 0.653521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.651666\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.712482\tvalid_0's binary_logloss: 0.660068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.654401\tvalid_0's binary_logloss: 0.646371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.693362\tvalid_0's binary_logloss: 0.616756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.623373\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.552329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.640891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.652834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.752525\tvalid_0's binary_logloss: 0.584608\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.816017\tvalid_0's binary_logloss: 0.541659\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.587302\tvalid_0's binary_logloss: 0.683151\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.663781\tvalid_0's binary_logloss: 0.661221\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.59076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.652444\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.594094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.757937\tvalid_0's binary_logloss: 0.674002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.733405\tvalid_0's binary_logloss: 0.666476\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.630534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.680375\tvalid_0's binary_logloss: 0.634565\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.641669\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.631105\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.641817\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.571429\tvalid_0's binary_logloss: 0.681183\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.78355\tvalid_0's binary_logloss: 0.553894\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.618412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.585859\tvalid_0's binary_logloss: 0.676893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.636337\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.631719\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.612554\tvalid_0's binary_logloss: 0.664367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's auc: 0.840548\tvalid_0's binary_logloss: 0.496264\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.596261\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.648698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.614457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.60101\tvalid_0's binary_logloss: 0.673859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.577628\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.554874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.623016\tvalid_0's binary_logloss: 0.662366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.60126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.624286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.609904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.645058\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.611733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.689394\tvalid_0's binary_logloss: 0.671329\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.619626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.670274\tvalid_0's binary_logloss: 0.660278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.608117\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.618625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.606782\tvalid_0's binary_logloss: 0.680599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.651486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.622626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.699134\tvalid_0's binary_logloss: 0.660947\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.655797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.652958\tvalid_0's binary_logloss: 0.645798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.608727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.774892\tvalid_0's binary_logloss: 0.629733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.658405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's auc: 0.829004\tvalid_0's binary_logloss: 0.51359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.546347\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.661313\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.78355\tvalid_0's binary_logloss: 0.56312\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's auc: 0.784271\tvalid_0's binary_logloss: 0.555657\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.628116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.622615\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.802309\tvalid_0's binary_logloss: 0.50738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's auc: 0.801587\tvalid_0's binary_logloss: 0.548647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.569987\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.643116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.62444\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.608586\tvalid_0's binary_logloss: 0.666359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.80303\tvalid_0's binary_logloss: 0.553978\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.664502\tvalid_0's binary_logloss: 0.654941\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.59772\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.677489\tvalid_0's binary_logloss: 0.628424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.607204\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.746032\tvalid_0's binary_logloss: 0.574114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.616276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.581276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.593785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.562921\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.644995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.739899\tvalid_0's binary_logloss: 0.650352\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.694084\tvalid_0's binary_logloss: 0.630458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.615003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.634622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.841991\tvalid_0's binary_logloss: 0.507523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.728355\tvalid_0's binary_logloss: 0.676846\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.66286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.629192\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.63149\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.573593\tvalid_0's binary_logloss: 0.677099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.732684\tvalid_0's binary_logloss: 0.668793\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.63365\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.635124\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.657287\tvalid_0's binary_logloss: 0.645876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.716089\tvalid_0's binary_logloss: 0.677659\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.568543\tvalid_0's binary_logloss: 0.68024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.581362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.59127\tvalid_0's binary_logloss: 0.678118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.612193\tvalid_0's binary_logloss: 0.663139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.621514\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.782107\tvalid_0's binary_logloss: 0.560717\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.557968\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.616691\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.815296\tvalid_0's binary_logloss: 0.512728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.468254\tvalid_0's binary_logloss: 0.687812\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.624098\tvalid_0's binary_logloss: 0.667135\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.608413\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.80303\tvalid_0's binary_logloss: 0.545289\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.512266\tvalid_0's binary_logloss: 0.685059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.708874\tvalid_0's binary_logloss: 0.676861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.75974\tvalid_0's binary_logloss: 0.672341\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.625541\tvalid_0's binary_logloss: 0.675269\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.585042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.629286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.621934\tvalid_0's binary_logloss: 0.656135\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.706349\tvalid_0's binary_logloss: 0.668913\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.700577\tvalid_0's binary_logloss: 0.628523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.61315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.634921\tvalid_0's binary_logloss: 0.65178\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.62039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.66811\tvalid_0's binary_logloss: 0.639554\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.585859\tvalid_0's binary_logloss: 0.681016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.793651\tvalid_0's binary_logloss: 0.550861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.61088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.772006\tvalid_0's binary_logloss: 0.63526\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.589747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.660299\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.632274\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.648268\tvalid_0's binary_logloss: 0.675915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.764791\tvalid_0's binary_logloss: 0.555631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.64557\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.615044\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.755411\tvalid_0's binary_logloss: 0.590989\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.589466\tvalid_0's binary_logloss: 0.673764\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.645743\tvalid_0's binary_logloss: 0.67139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.627292\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.77417\tvalid_0's binary_logloss: 0.556636\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.611391\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.582521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.626593\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.694084\tvalid_0's binary_logloss: 0.631906\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.616375\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.802309\tvalid_0's binary_logloss: 0.643669\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.810967\tvalid_0's binary_logloss: 0.594401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.795815\tvalid_0's binary_logloss: 0.548934\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.781385\tvalid_0's binary_logloss: 0.577277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.592015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.594471\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.588844\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.714286\tvalid_0's binary_logloss: 0.612647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.809524\tvalid_0's binary_logloss: 0.544713\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.571859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.605876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.7886\tvalid_0's binary_logloss: 0.578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.638528\tvalid_0's binary_logloss: 0.654541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.59857\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.632035\tvalid_0's binary_logloss: 0.668089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.72619\tvalid_0's binary_logloss: 0.666479\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.798701\tvalid_0's binary_logloss: 0.575175\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.621882\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.784993\tvalid_0's binary_logloss: 0.562804\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.63065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.649606\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.691558\tvalid_0's binary_logloss: 0.671897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.834776\tvalid_0's binary_logloss: 0.529791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.622227\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.609154\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.714286\tvalid_0's binary_logloss: 0.607461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.619114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.543709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.795815\tvalid_0's binary_logloss: 0.59172\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.694084\tvalid_0's binary_logloss: 0.636962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.721501\tvalid_0's binary_logloss: 0.600749\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.678932\tvalid_0's binary_logloss: 0.64147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.664502\tvalid_0's binary_logloss: 0.671297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.618154\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.664502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's auc: 0.803752\tvalid_0's binary_logloss: 0.536502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.602453\tvalid_0's binary_logloss: 0.675747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.620035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.622612\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.655844\tvalid_0's binary_logloss: 0.67938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.597821\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.624046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.636644\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.582787\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.611938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.83189\tvalid_0's binary_logloss: 0.610109\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.586512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.778499\tvalid_0's binary_logloss: 0.551721\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.626033\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.67316\tvalid_0's binary_logloss: 0.633763\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.797258\tvalid_0's binary_logloss: 0.555574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.609221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.80303\tvalid_0's binary_logloss: 0.625106\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.821789\tvalid_0's binary_logloss: 0.585599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.635521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.699134\tvalid_0's binary_logloss: 0.636866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.576479\tvalid_0's binary_logloss: 0.674581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.739177\tvalid_0's binary_logloss: 0.621754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.601732\tvalid_0's binary_logloss: 0.668782\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.618091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.636505\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.589706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.597297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.669553\tvalid_0's binary_logloss: 0.650362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.692641\tvalid_0's binary_logloss: 0.621324\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.652958\tvalid_0's binary_logloss: 0.658057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.625838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.656205\tvalid_0's binary_logloss: 0.679382\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.587505\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "17 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "3 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.601574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.625902\tvalid_0's binary_logloss: 0.662828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.613966\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.623978\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.599935\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.604052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.630193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.779942\tvalid_0's binary_logloss: 0.57348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.58583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.749639\tvalid_0's binary_logloss: 0.586121\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.592875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.602139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.648317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.598607\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.608469\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.624195\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.720418\tvalid_0's binary_logloss: 0.64832\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.622076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.739899\tvalid_0's binary_logloss: 0.654087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.618326\tvalid_0's binary_logloss: 0.673401\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.601732\tvalid_0's binary_logloss: 0.669452\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.626984\tvalid_0's binary_logloss: 0.661115\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.678116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.718975\tvalid_0's binary_logloss: 0.618463\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.587241\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.654662\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's auc: 0.854978\tvalid_0's binary_logloss: 0.478119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.624098\tvalid_0's binary_logloss: 0.673175\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.635805\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.60966\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.653727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.620594\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.661616\tvalid_0's binary_logloss: 0.660573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.630432\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.626263\tvalid_0's binary_logloss: 0.67969\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.758297\tvalid_0's binary_logloss: 0.584104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.67785\tvalid_0's binary_logloss: 0.676133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.6086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.660895\tvalid_0's binary_logloss: 0.65055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.58287\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.600214\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.677128\tvalid_0's binary_logloss: 0.650457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.553664\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.667027\tvalid_0's binary_logloss: 0.652617\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.778139\tvalid_0's binary_logloss: 0.672495\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.699856\tvalid_0's binary_logloss: 0.611134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.616099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.634522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.664502\tvalid_0's binary_logloss: 0.64945\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.663781\tvalid_0's binary_logloss: 0.646463\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.669983\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.601725\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.648218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.732684\tvalid_0's binary_logloss: 0.666955\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.599485\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.576118\tvalid_0's binary_logloss: 0.682636\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.598064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.596559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.630231\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.643939\tvalid_0's binary_logloss: 0.658812\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.587728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.736291\tvalid_0's binary_logloss: 0.641092\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.68759\tvalid_0's binary_logloss: 0.651648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.661241\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.582614\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.599099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.579242\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.786436\tvalid_0's binary_logloss: 0.547181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.559732\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.622008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's auc: 0.860029\tvalid_0's binary_logloss: 0.480802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.592875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.652035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.596118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.650003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.789322\tvalid_0's binary_logloss: 0.573042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.627064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.648901\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's auc: 0.784993\tvalid_0's binary_logloss: 0.559117\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.648445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.649351\tvalid_0's binary_logloss: 0.654525\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.541126\tvalid_0's binary_logloss: 0.682382\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.661255\tvalid_0's binary_logloss: 0.679437\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.635642\tvalid_0's binary_logloss: 0.668122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.594536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.815296\tvalid_0's binary_logloss: 0.561933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.581169\tvalid_0's binary_logloss: 0.675167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.659831\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.593015\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.654014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.622798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.615728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.626643\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.573593\tvalid_0's binary_logloss: 0.673093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.631375\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's auc: 0.778499\tvalid_0's binary_logloss: 0.585082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.653914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.7114\tvalid_0's binary_logloss: 0.619981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.606528\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.631021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.688312\tvalid_0's binary_logloss: 0.638363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.635582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.633478\tvalid_0's binary_logloss: 0.672979\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.622655\tvalid_0's binary_logloss: 0.664956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.628354\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.637834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.650705\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.593118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.614655\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.609239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.58658\tvalid_0's binary_logloss: 0.66985\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's auc: 0.805916\tvalid_0's binary_logloss: 0.518026\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.680736\tvalid_0's binary_logloss: 0.674573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.624657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.678932\tvalid_0's binary_logloss: 0.664469\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.642136\tvalid_0's binary_logloss: 0.657118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.652059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.599206\tvalid_0's binary_logloss: 0.676273\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.645022\tvalid_0's binary_logloss: 0.655255\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.80303\tvalid_0's binary_logloss: 0.62194\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.626759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.79798\tvalid_0's binary_logloss: 0.56078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.626622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.566974\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.718975\tvalid_0's binary_logloss: 0.670983\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.670996\tvalid_0's binary_logloss: 0.656755\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.602376\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.617474\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.678801\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.646536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.666176\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.634186\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.477273\tvalid_0's binary_logloss: 0.687049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.631278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.785714\tvalid_0's binary_logloss: 0.562827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.6829\tvalid_0's binary_logloss: 0.646807\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.77417\tvalid_0's binary_logloss: 0.563264\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.775613\tvalid_0's binary_logloss: 0.560415\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.76912\tvalid_0's binary_logloss: 0.63898\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.804473\tvalid_0's binary_logloss: 0.523184\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.639971\tvalid_0's binary_logloss: 0.653232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.769841\tvalid_0's binary_logloss: 0.555383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.708874\tvalid_0's binary_logloss: 0.64868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.688312\tvalid_0's binary_logloss: 0.662283\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.635301\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.630105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's auc: 0.807359\tvalid_0's binary_logloss: 0.552152\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.660415\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.571068\tvalid_0's binary_logloss: 0.675708\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.545094\tvalid_0's binary_logloss: 0.682804\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.640754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.622749\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.68759\tvalid_0's binary_logloss: 0.648284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.601031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.645022\tvalid_0's binary_logloss: 0.654134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.644767\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.564935\tvalid_0's binary_logloss: 0.675853\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.670635\tvalid_0's binary_logloss: 0.663543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.608023\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.646907\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.688312\tvalid_0's binary_logloss: 0.641715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.795815\tvalid_0's binary_logloss: 0.551136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.658009\tvalid_0's binary_logloss: 0.659649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.635001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.618362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.654602\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.816017\tvalid_0's binary_logloss: 0.645106\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.669553\tvalid_0's binary_logloss: 0.65393\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.779221\tvalid_0's binary_logloss: 0.576419\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.779221\tvalid_0's binary_logloss: 0.589944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.521645\tvalid_0's binary_logloss: 0.684948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.686508\tvalid_0's binary_logloss: 0.663361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.638516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.794372\tvalid_0's binary_logloss: 0.5907\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.57574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.594414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.660243\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.667749\tvalid_0's binary_logloss: 0.673981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.640681\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.629252\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.591738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.57474\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.638955\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.645022\tvalid_0's binary_logloss: 0.675024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.838384\tvalid_0's binary_logloss: 0.621031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.661616\tvalid_0's binary_logloss: 0.642795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.621205\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.625079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.702381\tvalid_0's binary_logloss: 0.637051\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's auc: 0.808081\tvalid_0's binary_logloss: 0.552898\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.656205\tvalid_0's binary_logloss: 0.654414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.606818\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.59592\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.68759\tvalid_0's binary_logloss: 0.630614\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.665945\tvalid_0's binary_logloss: 0.637728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.597641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.680375\tvalid_0's binary_logloss: 0.644008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.643043\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.634159\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.638675\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.599979\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.624984\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.655844\tvalid_0's binary_logloss: 0.641049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.749639\tvalid_0's binary_logloss: 0.622949\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.782107\tvalid_0's binary_logloss: 0.552996\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.623249\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.704906\tvalid_0's binary_logloss: 0.623064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.601298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.653064\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.652442\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.656926\tvalid_0's binary_logloss: 0.671627\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.639971\tvalid_0's binary_logloss: 0.650896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.600024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.606293\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.591873\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.683983\tvalid_0's binary_logloss: 0.637045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.603699\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.673882\tvalid_0's binary_logloss: 0.634014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.787879\tvalid_0's binary_logloss: 0.590977\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.797258\tvalid_0's binary_logloss: 0.586582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.639922\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.629149\tvalid_0's binary_logloss: 0.677351\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.6114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.604606\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.572872\tvalid_0's binary_logloss: 0.681997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.585116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.768398\tvalid_0's binary_logloss: 0.593727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.721501\tvalid_0's binary_logloss: 0.617383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.808802\tvalid_0's binary_logloss: 0.547643\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.585137\tvalid_0's binary_logloss: 0.678846\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.792929\tvalid_0's binary_logloss: 0.561218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.766955\tvalid_0's binary_logloss: 0.592025\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.811688\tvalid_0's binary_logloss: 0.523104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.667746\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.683622\tvalid_0's binary_logloss: 0.665281\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.618326\tvalid_0's binary_logloss: 0.667956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.834416\tvalid_0's binary_logloss: 0.659681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.627179\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.625994\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.609406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.566739\tvalid_0's binary_logloss: 0.677327\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.605909\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.699134\tvalid_0's binary_logloss: 0.623642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.638167\tvalid_0's binary_logloss: 0.664565\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.577681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.832612\tvalid_0's binary_logloss: 0.517324\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.765873\tvalid_0's binary_logloss: 0.596303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.685065\tvalid_0's binary_logloss: 0.632193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.661977\tvalid_0's binary_logloss: 0.67193\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.827561\tvalid_0's binary_logloss: 0.550099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.670559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.7886\tvalid_0's binary_logloss: 0.631839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.589466\tvalid_0's binary_logloss: 0.681312\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.614788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.813131\tvalid_0's binary_logloss: 0.533984\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.618957\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.610665\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's auc: 0.800866\tvalid_0's binary_logloss: 0.527196\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.574065\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.632314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.774892\tvalid_0's binary_logloss: 0.572573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.616125\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.623927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.623486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.641527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.67785\tvalid_0's binary_logloss: 0.653755\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.63925\tvalid_0's binary_logloss: 0.660127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.691558\tvalid_0's binary_logloss: 0.676826\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.600031\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.35 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.787879\tvalid_0's binary_logloss: 0.55461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's auc: 0.802309\tvalid_0's binary_logloss: 0.527409\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.664618\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.728355\tvalid_0's binary_logloss: 0.675836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.659812\tvalid_0's binary_logloss: 0.679463\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.608255\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.63538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.628025\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.640127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's auc: 0.847763\tvalid_0's binary_logloss: 0.462538\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.594156\tvalid_0's binary_logloss: 0.671129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.669553\tvalid_0's binary_logloss: 0.646282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.746032\tvalid_0's binary_logloss: 0.59698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.626263\tvalid_0's binary_logloss: 0.661973\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.64917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.565308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.69228\tvalid_0's binary_logloss: 0.677752\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.748196\tvalid_0's binary_logloss: 0.593733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.543651\tvalid_0's binary_logloss: 0.681498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.760101\tvalid_0's binary_logloss: 0.67013\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "14 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 14 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.629149\tvalid_0's binary_logloss: 0.654647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.592352\tvalid_0's binary_logloss: 0.670462\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.566461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.699856\tvalid_0's binary_logloss: 0.672481\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.681457\tvalid_0's binary_logloss: 0.678803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.648464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.693723\tvalid_0's binary_logloss: 0.676902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.599703\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.698773\tvalid_0's binary_logloss: 0.645371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.636802\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.704906\tvalid_0's binary_logloss: 0.628611\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.625203\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.636914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.749639\tvalid_0's binary_logloss: 0.580232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.688312\tvalid_0's binary_logloss: 0.6423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.633297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.678932\tvalid_0's binary_logloss: 0.649091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.750722\tvalid_0's binary_logloss: 0.632949\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.59783\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.517677\tvalid_0's binary_logloss: 0.685382\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.686869\tvalid_0's binary_logloss: 0.639831\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.618827\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.635642\tvalid_0's binary_logloss: 0.655536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.604572\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.663059\tvalid_0's binary_logloss: 0.645841\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.775613\tvalid_0's binary_logloss: 0.579797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.631115\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.593074\tvalid_0's binary_logloss: 0.678697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.614879\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.746753\tvalid_0's binary_logloss: 0.604113\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.556277\tvalid_0's binary_logloss: 0.680714\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.632756\tvalid_0's binary_logloss: 0.66211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.670996\tvalid_0's binary_logloss: 0.640032\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.649233\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.610566\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.589011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.700577\tvalid_0's binary_logloss: 0.617654\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.600001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.680375\tvalid_0's binary_logloss: 0.658089\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.65873\tvalid_0's binary_logloss: 0.656719\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.776335\tvalid_0's binary_logloss: 0.554386\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.777056\tvalid_0's binary_logloss: 0.585861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.650193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.64246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.644661\tvalid_0's binary_logloss: 0.659672\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.613611\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.677489\tvalid_0's binary_logloss: 0.658275\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.818182\tvalid_0's binary_logloss: 0.576405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.620032\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.585389\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.619528\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.764069\tvalid_0's binary_logloss: 0.635194\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.831169\tvalid_0's binary_logloss: 0.519859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.630502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.676299\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.624791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.65488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.611663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.859307\tvalid_0's binary_logloss: 0.448788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.746392\tvalid_0's binary_logloss: 0.655191\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "17 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "3 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.693362\tvalid_0's binary_logloss: 0.615243\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.724387\tvalid_0's binary_logloss: 0.61091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.683983\tvalid_0's binary_logloss: 0.63417\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.820346\tvalid_0's binary_logloss: 0.518182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.629501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.617605\tvalid_0's binary_logloss: 0.668222\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.642496\tvalid_0's binary_logloss: 0.666552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.764069\tvalid_0's binary_logloss: 0.588347\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.616489\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.656931\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.727633\tvalid_0's binary_logloss: 0.676581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.652543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.757576\tvalid_0's binary_logloss: 0.574361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's auc: 0.805195\tvalid_0's binary_logloss: 0.543706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.604468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.623339\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.625919\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's auc: 0.742424\tvalid_0's binary_logloss: 0.600879\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.610007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.795094\tvalid_0's binary_logloss: 0.544009\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.619226\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.608947\tvalid_0's binary_logloss: 0.670015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.699856\tvalid_0's binary_logloss: 0.632912\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.63458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.658112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.648681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.643766\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.620236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.679496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.613276\tvalid_0's binary_logloss: 0.668286\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.65987\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.683983\tvalid_0's binary_logloss: 0.627537\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.582701\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.62662\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.66811\tvalid_0's binary_logloss: 0.650668\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.785714\tvalid_0's binary_logloss: 0.581397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.739177\tvalid_0's binary_logloss: 0.634871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.62808\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.746032\tvalid_0's binary_logloss: 0.586263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.746032\tvalid_0's binary_logloss: 0.597919\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.621016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.628911\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.605339\tvalid_0's binary_logloss: 0.668403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.588333\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.646774\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.805195\tvalid_0's binary_logloss: 0.571145\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.621769\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.679339\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.635697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.516955\tvalid_0's binary_logloss: 0.685246\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.755411\tvalid_0's binary_logloss: 0.636523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.605914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.702381\tvalid_0's binary_logloss: 0.648931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.607448\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.624433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's auc: 0.810245\tvalid_0's binary_logloss: 0.567042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.704906\tvalid_0's binary_logloss: 0.640261\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's auc: 0.880952\tvalid_0's binary_logloss: 0.439357\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.742785\tvalid_0's binary_logloss: 0.635045\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.592415\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.79798\tvalid_0's binary_logloss: 0.554896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.714286\tvalid_0's binary_logloss: 0.617748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.670635\tvalid_0's binary_logloss: 0.678545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.632035\tvalid_0's binary_logloss: 0.660359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.601835\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.822511\tvalid_0's binary_logloss: 0.538825\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.667749\tvalid_0's binary_logloss: 0.670425\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.62017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.587998\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.558654\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.577117\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.830447\tvalid_0's binary_logloss: 0.505861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.612626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's auc: 0.857864\tvalid_0's binary_logloss: 0.464508\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.589422\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.750722\tvalid_0's binary_logloss: 0.646897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.477633\tvalid_0's binary_logloss: 0.688051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.559958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.799423\tvalid_0's binary_logloss: 0.540295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.658009\tvalid_0's binary_logloss: 0.650266\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.613977\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.610029\tvalid_0's binary_logloss: 0.675489\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.633006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.63231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.838384\tvalid_0's binary_logloss: 0.544819\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.710317\tvalid_0's binary_logloss: 0.661194\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.594048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.513709\tvalid_0's binary_logloss: 0.686569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's auc: 0.826118\tvalid_0's binary_logloss: 0.528053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.637492\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.586922\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.670274\tvalid_0's binary_logloss: 0.632684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.645743\tvalid_0's binary_logloss: 0.65886\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.62001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.658381\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.662909\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.596849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.795094\tvalid_0's binary_logloss: 0.554641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.62204\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.597743\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.764791\tvalid_0's binary_logloss: 0.595272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.619263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.617924\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.758297\tvalid_0's binary_logloss: 0.581016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.621746\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.797258\tvalid_0's binary_logloss: 0.551335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.663781\tvalid_0's binary_logloss: 0.645557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.670996\tvalid_0's binary_logloss: 0.640346\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.604618\tvalid_0's binary_logloss: 0.669923\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.646928\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.576877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.629304\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's auc: 0.789322\tvalid_0's binary_logloss: 0.591902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.577834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.617363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.599167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.757215\tvalid_0's binary_logloss: 0.667458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.629041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.682179\tvalid_0's binary_logloss: 0.642685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.586079\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's auc: 0.843434\tvalid_0's binary_logloss: 0.494798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.650445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.645673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.571534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.724026\tvalid_0's binary_logloss: 0.633081\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.721861\tvalid_0's binary_logloss: 0.631536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.555221\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.638641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.637507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.61481\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.721501\tvalid_0's binary_logloss: 0.635762\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.614212\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.634354\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.604163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.680736\tvalid_0's binary_logloss: 0.677586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.73557\tvalid_0's binary_logloss: 0.648774\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.575288\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.638527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.61039\tvalid_0's binary_logloss: 0.666043\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.654401\tvalid_0's binary_logloss: 0.654642\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.650794\tvalid_0's binary_logloss: 0.656488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.679293\tvalid_0's binary_logloss: 0.678397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.633478\tvalid_0's binary_logloss: 0.666042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.618546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.592261\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.617256\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.601442\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.749639\tvalid_0's binary_logloss: 0.606929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.632368\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.782107\tvalid_0's binary_logloss: 0.550567\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.627622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.603668\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.618553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.784993\tvalid_0's binary_logloss: 0.570641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.632218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.595006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.626984\tvalid_0's binary_logloss: 0.664013\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's auc: 0.75974\tvalid_0's binary_logloss: 0.572198\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.598687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.790765\tvalid_0's binary_logloss: 0.546221\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.691198\tvalid_0's binary_logloss: 0.632237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.584679\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.658369\tvalid_0's binary_logloss: 0.679443\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.883117\tvalid_0's binary_logloss: 0.441226\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.680736\tvalid_0's binary_logloss: 0.672384\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.769841\tvalid_0's binary_logloss: 0.593888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.668951\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.606338\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.560758\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.588024\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.792929\tvalid_0's binary_logloss: 0.60181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.582348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.668146\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.642136\tvalid_0's binary_logloss: 0.648455\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.58571\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.655777\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.692641\tvalid_0's binary_logloss: 0.633547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.589827\tvalid_0's binary_logloss: 0.67631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's auc: 0.811688\tvalid_0's binary_logloss: 0.521477\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.573593\tvalid_0's binary_logloss: 0.678887\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.828283\tvalid_0's binary_logloss: 0.525067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.60101\tvalid_0's binary_logloss: 0.66743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.614935\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.594156\tvalid_0's binary_logloss: 0.671657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.676742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.59016\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.577735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.631313\tvalid_0's binary_logloss: 0.660414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.666667\tvalid_0's binary_logloss: 0.643664\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.647301\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.814574\tvalid_0's binary_logloss: 0.552424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.650682\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.600087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.787157\tvalid_0's binary_logloss: 0.560942\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.774892\tvalid_0's binary_logloss: 0.611753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.630164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.572511\tvalid_0's binary_logloss: 0.682703\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.636271\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.596231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.578136\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.675218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.620771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.532107\tvalid_0's binary_logloss: 0.68038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.6763\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.641414\tvalid_0's binary_logloss: 0.659942\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.628968\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.642136\tvalid_0's binary_logloss: 0.662394\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.807359\tvalid_0's binary_logloss: 0.540307\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.607325\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.802309\tvalid_0's binary_logloss: 0.540992\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.602092\tvalid_0's binary_logloss: 0.673883\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.768398\tvalid_0's binary_logloss: 0.600262\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.64718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.651974\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.59596\tvalid_0's binary_logloss: 0.67786\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.811688\tvalid_0's binary_logloss: 0.634833\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.62639\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.632883\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.724387\tvalid_0's binary_logloss: 0.613464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.61457\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.628884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.569095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.631932\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.588023\tvalid_0's binary_logloss: 0.675427\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.676233\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.653218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.790765\tvalid_0's binary_logloss: 0.541582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.631853\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.475469\tvalid_0's binary_logloss: 0.687482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.619474\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.636483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.624098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.620576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.6012\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.77417\tvalid_0's binary_logloss: 0.594201\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.616245\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.602475\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.640693\tvalid_0's binary_logloss: 0.650761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.766955\tvalid_0's binary_logloss: 0.568469\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.61106\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's auc: 0.823232\tvalid_0's binary_logloss: 0.531989\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.652281\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.629227\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.640806\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.667749\tvalid_0's binary_logloss: 0.662759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.799423\tvalid_0's binary_logloss: 0.558356\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.647433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.608774\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.662914\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.614627\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.7114\tvalid_0's binary_logloss: 0.638795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.724387\tvalid_0's binary_logloss: 0.611699\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.659405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.828283\tvalid_0's binary_logloss: 0.544708\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.572619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.632257\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.602024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.619326\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.678211\tvalid_0's binary_logloss: 0.6368\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.603003\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.800144\tvalid_0's binary_logloss: 0.543196\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.718975\tvalid_0's binary_logloss: 0.670236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.591715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.731602\tvalid_0's binary_logloss: 0.606965\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.478716\tvalid_0's binary_logloss: 0.689963\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.772006\tvalid_0's binary_logloss: 0.560443\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.619073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.628066\tvalid_0's binary_logloss: 0.679493\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.724387\tvalid_0's binary_logloss: 0.629258\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.6443\tvalid_0's binary_logloss: 0.645688\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.641114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.59502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.797258\tvalid_0's binary_logloss: 0.570022\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.637446\tvalid_0's binary_logloss: 0.654194\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.626545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.626263\tvalid_0's binary_logloss: 0.659877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.60438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.653696\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.609307\tvalid_0's binary_logloss: 0.675272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.623383\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.611495\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.714286\tvalid_0's binary_logloss: 0.616054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.746753\tvalid_0's binary_logloss: 0.598267\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.621212\tvalid_0's binary_logloss: 0.663036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.605185\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.63072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.582973\tvalid_0's binary_logloss: 0.671047\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.603604\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.724026\tvalid_0's binary_logloss: 0.676688\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.569698\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.50469\tvalid_0's binary_logloss: 0.686622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.615771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.590647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.58956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.627706\tvalid_0's binary_logloss: 0.666142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.634838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.613028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.613997\tvalid_0's binary_logloss: 0.676514\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.633838\tvalid_0's binary_logloss: 0.667103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.66811\tvalid_0's binary_logloss: 0.668421\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.668027\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.612243\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.651933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.616301\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.591543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.595064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.613053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.578504\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.608064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's auc: 0.753968\tvalid_0's binary_logloss: 0.576792\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.609447\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.801587\tvalid_0's binary_logloss: 0.532176\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.678211\tvalid_0's binary_logloss: 0.631198\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.597953\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.64097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.602951\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.609315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.78355\tvalid_0's binary_logloss: 0.585648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.537174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.878066\tvalid_0's binary_logloss: 0.475333\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.615241\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.661161\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.653267\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.617684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.622471\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.636364\tvalid_0's binary_logloss: 0.677005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.746032\tvalid_0's binary_logloss: 0.616272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.650072\tvalid_0's binary_logloss: 0.654534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.679929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.65012\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.594753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.598366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.779942\tvalid_0's binary_logloss: 0.574701\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.612858\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.591244\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.597697\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.64162\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.768398\tvalid_0's binary_logloss: 0.578313\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.571429\tvalid_0's binary_logloss: 0.674551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.636052\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.638822\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.631927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.585874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.680375\tvalid_0's binary_logloss: 0.637353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.652958\tvalid_0's binary_logloss: 0.659359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.76912\tvalid_0's binary_logloss: 0.568137\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.6211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.729437\tvalid_0's binary_logloss: 0.60954\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.683983\tvalid_0's binary_logloss: 0.64244\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.643651\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.611928\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.604641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.672439\tvalid_0's binary_logloss: 0.646112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.767316\tvalid_0's binary_logloss: 0.624899\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.665411\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's auc: 0.807359\tvalid_0's binary_logloss: 0.555906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.676407\tvalid_0's binary_logloss: 0.6785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.595516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.619392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.610051\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.630405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.521645\tvalid_0's binary_logloss: 0.684242\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.612996\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.667921\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.621934\tvalid_0's binary_logloss: 0.661833\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.664141\tvalid_0's binary_logloss: 0.650728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.76912\tvalid_0's binary_logloss: 0.58488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.781385\tvalid_0's binary_logloss: 0.560702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.621515\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.752165\tvalid_0's binary_logloss: 0.664166\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.779942\tvalid_0's binary_logloss: 0.608626\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.787157\tvalid_0's binary_logloss: 0.564922\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.626622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.597499\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.621594\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.619026\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.612915\tvalid_0's binary_logloss: 0.682594\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.565069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's auc: 0.717172\tvalid_0's binary_logloss: 0.646086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.599399\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.65749\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.760462\tvalid_0's binary_logloss: 0.580868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.704545\tvalid_0's binary_logloss: 0.654376\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.652958\tvalid_0's binary_logloss: 0.6552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.768398\tvalid_0's binary_logloss: 0.634128\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.770563\tvalid_0's binary_logloss: 0.576411\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.600802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.616883\tvalid_0's binary_logloss: 0.659105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.826118\tvalid_0's binary_logloss: 0.621673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.613816\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.7114\tvalid_0's binary_logloss: 0.662492\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.627322\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.627612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.58658\tvalid_0's binary_logloss: 0.672363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.661021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.633478\tvalid_0's binary_logloss: 0.670373\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.630249\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.685426\tvalid_0's binary_logloss: 0.633986\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.650794\tvalid_0's binary_logloss: 0.66862\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.706349\tvalid_0's binary_logloss: 0.643269\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.665945\tvalid_0's binary_logloss: 0.643401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.622655\tvalid_0's binary_logloss: 0.669184\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.647031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.644632\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.658009\tvalid_0's binary_logloss: 0.638048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.802309\tvalid_0's binary_logloss: 0.564743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.579235\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.647316\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.777056\tvalid_0's binary_logloss: 0.563261\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.619769\tvalid_0's binary_logloss: 0.670085\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's auc: 0.776335\tvalid_0's binary_logloss: 0.591148\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.598949\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.670996\tvalid_0's binary_logloss: 0.642192\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.596035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.699134\tvalid_0's binary_logloss: 0.623771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.786436\tvalid_0's binary_logloss: 0.667583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.65873\tvalid_0's binary_logloss: 0.67796\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.613276\tvalid_0's binary_logloss: 0.667193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.595238\tvalid_0's binary_logloss: 0.672314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.588688\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.692641\tvalid_0's binary_logloss: 0.615596\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.679372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.618326\tvalid_0's binary_logloss: 0.666249\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.627706\tvalid_0's binary_logloss: 0.66083\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.757215\tvalid_0's binary_logloss: 0.651992\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.610119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.591611\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.598761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.758658\tvalid_0's binary_logloss: 0.623808\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.610597\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.607482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.614443\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.664844\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.647164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.660534\tvalid_0's binary_logloss: 0.645032\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.607971\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.623377\tvalid_0's binary_logloss: 0.659816\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.630103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.651515\tvalid_0's binary_logloss: 0.650253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.593712\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's auc: 0.749639\tvalid_0's binary_logloss: 0.581429\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.647547\tvalid_0's binary_logloss: 0.675288\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.613673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.653069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.634928\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.5386\tvalid_0's binary_logloss: 0.683706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's auc: 0.804473\tvalid_0's binary_logloss: 0.524757\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.631865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.728355\tvalid_0's binary_logloss: 0.654118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.633616\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.64851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.692641\tvalid_0's binary_logloss: 0.646829\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.632929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.636476\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.766955\tvalid_0's binary_logloss: 0.579552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.650072\tvalid_0's binary_logloss: 0.654538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.752525\tvalid_0's binary_logloss: 0.609751\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.590909\tvalid_0's binary_logloss: 0.67291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.660895\tvalid_0's binary_logloss: 0.65731\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.672439\tvalid_0's binary_logloss: 0.639376\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.700216\tvalid_0's binary_logloss: 0.677392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.639401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.620127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.609586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.599134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.609978\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.644436\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.57282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.608717\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.663059\tvalid_0's binary_logloss: 0.656246\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.66727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's auc: 0.785714\tvalid_0's binary_logloss: 0.554398\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.601438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's auc: 0.782828\tvalid_0's binary_logloss: 0.596628\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.620568\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.642857\tvalid_0's binary_logloss: 0.674688\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's auc: 0.779221\tvalid_0's binary_logloss: 0.56756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.655123\tvalid_0's binary_logloss: 0.64383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.60486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.666306\tvalid_0's binary_logloss: 0.674895\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[364]\tvalid_0's auc: 0.891053\tvalid_0's binary_logloss: 0.407462\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.673295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.760462\tvalid_0's binary_logloss: 0.582456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.612583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's auc: 0.847042\tvalid_0's binary_logloss: 0.493015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.635353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.602453\tvalid_0's binary_logloss: 0.667899\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.686869\tvalid_0's binary_logloss: 0.630595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.626962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.612323\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "17 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "3 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "4 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 4 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.606642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.714286\tvalid_0's binary_logloss: 0.606393\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.80303\tvalid_0's binary_logloss: 0.54962\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.664502\tvalid_0's binary_logloss: 0.637458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.580808\tvalid_0's binary_logloss: 0.667702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.638798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.774892\tvalid_0's binary_logloss: 0.571226\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.669553\tvalid_0's binary_logloss: 0.642994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.588705\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.592652\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "14 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 14 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.602748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.594655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.644139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.585974\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.737374\tvalid_0's binary_logloss: 0.637362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.606583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.601864\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.654401\tvalid_0's binary_logloss: 0.646941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.63925\tvalid_0's binary_logloss: 0.651408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.624779\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.692641\tvalid_0's binary_logloss: 0.630461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.818182\tvalid_0's binary_logloss: 0.530873\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.653819\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.693362\tvalid_0's binary_logloss: 0.639649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.661278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.685786\tvalid_0's binary_logloss: 0.677433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.612999\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.597278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.613144\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.598387\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.691198\tvalid_0's binary_logloss: 0.636898\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's auc: 0.810967\tvalid_0's binary_logloss: 0.544163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.613115\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.643579\tvalid_0's binary_logloss: 0.663571\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.756133\tvalid_0's binary_logloss: 0.586915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.620644\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.611472\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.766955\tvalid_0's binary_logloss: 0.573498\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.613933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.624851\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.662338\tvalid_0's binary_logloss: 0.637327\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.641383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.614428\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.588023\tvalid_0's binary_logloss: 0.674343\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.633838\tvalid_0's binary_logloss: 0.672035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.691198\tvalid_0's binary_logloss: 0.63052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.648629\tvalid_0's binary_logloss: 0.650944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.666667\tvalid_0's binary_logloss: 0.664729\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.626184\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.648531\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.763348\tvalid_0's binary_logloss: 0.577314\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.643786\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.746753\tvalid_0's binary_logloss: 0.594677\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.63437\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.691558\tvalid_0's binary_logloss: 0.655997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.637085\tvalid_0's binary_logloss: 0.652827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.651533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.703102\tvalid_0's binary_logloss: 0.629809\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.668831\tvalid_0's binary_logloss: 0.651728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.750722\tvalid_0's binary_logloss: 0.636156\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "4 features with a correlation magnitude greater than 0.35.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.638889\tvalid_0's binary_logloss: 0.679355\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's auc: 0.808081\tvalid_0's binary_logloss: 0.545655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.782828\tvalid_0's binary_logloss: 0.663399\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.768759\tvalid_0's binary_logloss: 0.627272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.755411\tvalid_0's binary_logloss: 0.599263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.779942\tvalid_0's binary_logloss: 0.570046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.505411\tvalid_0's binary_logloss: 0.684785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.618634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.678932\tvalid_0's binary_logloss: 0.634621\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.670274\tvalid_0's binary_logloss: 0.644626\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.593436\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.700216\tvalid_0's binary_logloss: 0.667051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.7886\tvalid_0's binary_logloss: 0.601052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.637807\tvalid_0's binary_logloss: 0.67202\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.624098\tvalid_0's binary_logloss: 0.657613\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.62007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.627788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.782828\tvalid_0's binary_logloss: 0.634007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.75469\tvalid_0's binary_logloss: 0.643035\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.630592\tvalid_0's binary_logloss: 0.656192\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "13 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 13 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.811688\tvalid_0's binary_logloss: 0.549332\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.597011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's auc: 0.758297\tvalid_0's binary_logloss: 0.555195\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.649351\tvalid_0's binary_logloss: 0.674061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.606782\tvalid_0's binary_logloss: 0.679075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.574675\tvalid_0's binary_logloss: 0.683356\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.71645\tvalid_0's binary_logloss: 0.647849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.794372\tvalid_0's binary_logloss: 0.640447\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.602611\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.655844\tvalid_0's binary_logloss: 0.651\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.816739\tvalid_0's binary_logloss: 0.60263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.623219\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.611833\tvalid_0's binary_logloss: 0.661626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.619957\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.547252\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.771645\tvalid_0's binary_logloss: 0.655949\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.619038\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.578684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.628315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.65865\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.658009\tvalid_0's binary_logloss: 0.679682\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.705267\tvalid_0's binary_logloss: 0.669631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.660895\tvalid_0's binary_logloss: 0.638367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.642498\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.669553\tvalid_0's binary_logloss: 0.667423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.607556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.654401\tvalid_0's binary_logloss: 0.654667\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.621271\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.616728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.617825\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.618026\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.725108\tvalid_0's binary_logloss: 0.622283\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.575036\tvalid_0's binary_logloss: 0.670405\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.642857\tvalid_0's binary_logloss: 0.667846\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.620116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.77417\tvalid_0's binary_logloss: 0.558472\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.787879\tvalid_0's binary_logloss: 0.550716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.614939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.625541\tvalid_0's binary_logloss: 0.659912\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.564346\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.604635\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.772727\tvalid_0's binary_logloss: 0.600297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.608874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.683983\tvalid_0's binary_logloss: 0.645934\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.598716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.601667\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's auc: 0.816739\tvalid_0's binary_logloss: 0.516447\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.625582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.620169\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.628491\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.40.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.733405\tvalid_0's binary_logloss: 0.637618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.67316\tvalid_0's binary_logloss: 0.637903\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.79798\tvalid_0's binary_logloss: 0.605409\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.758297\tvalid_0's binary_logloss: 0.594272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.580907\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's auc: 0.834055\tvalid_0's binary_logloss: 0.502531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.591627\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.59674\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's auc: 0.883117\tvalid_0's binary_logloss: 0.413406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.815296\tvalid_0's binary_logloss: 0.524727\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.632035\tvalid_0's binary_logloss: 0.669389\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.627678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.606129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.622668\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.647186\tvalid_0's binary_logloss: 0.644747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.731602\tvalid_0's binary_logloss: 0.649865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.76912\tvalid_0's binary_logloss: 0.596169\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.641418\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.5788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.779942\tvalid_0's binary_logloss: 0.615822\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.492063\tvalid_0's binary_logloss: 0.687696\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.653674\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's auc: 0.748918\tvalid_0's binary_logloss: 0.573677\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.600649\tvalid_0's binary_logloss: 0.674496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.658608\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.616596\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.761905\tvalid_0's binary_logloss: 0.594348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.813131\tvalid_0's binary_logloss: 0.560556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.60101\tvalid_0's binary_logloss: 0.674736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.564581\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.580475\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.626696\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.611108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.808802\tvalid_0's binary_logloss: 0.561128\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.835498\tvalid_0's binary_logloss: 0.517909\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.609199\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.614715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.607622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.762626\tvalid_0's binary_logloss: 0.604237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.677128\tvalid_0's binary_logloss: 0.649706\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.635855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.60608\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.60181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.615831\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.59127\tvalid_0's binary_logloss: 0.682053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's auc: 0.800144\tvalid_0's binary_logloss: 0.549392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.58168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.672439\tvalid_0's binary_logloss: 0.647859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.635853\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.497114\tvalid_0's binary_logloss: 0.687467\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.830447\tvalid_0's binary_logloss: 0.523043\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.60558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.7114\tvalid_0's binary_logloss: 0.627359\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.650072\tvalid_0's binary_logloss: 0.650073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.671717\tvalid_0's binary_logloss: 0.641322\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.651372\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.713203\tvalid_0's binary_logloss: 0.653564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.757576\tvalid_0's binary_logloss: 0.592999\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.611833\tvalid_0's binary_logloss: 0.666851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.643579\tvalid_0's binary_logloss: 0.650458\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.757576\tvalid_0's binary_logloss: 0.579464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.630295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.607481\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.619645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.63746\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.639867\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.67785\tvalid_0's binary_logloss: 0.66722\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.645351\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.599206\tvalid_0's binary_logloss: 0.672071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.776335\tvalid_0's binary_logloss: 0.563149\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.45.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.623539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.665388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.624098\tvalid_0's binary_logloss: 0.660496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.652931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.766234\tvalid_0's binary_logloss: 0.640508\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.79798\tvalid_0's binary_logloss: 0.542443\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.705628\tvalid_0's binary_logloss: 0.638936\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.607434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.774892\tvalid_0's binary_logloss: 0.568349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.586793\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "17 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "3 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.73557\tvalid_0's binary_logloss: 0.660836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.625202\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.647646\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.744228\tvalid_0's binary_logloss: 0.675993\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.578644\tvalid_0's binary_logloss: 0.671201\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.498196\tvalid_0's binary_logloss: 0.686625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.630233\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.597287\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.647518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.62743\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.660895\tvalid_0's binary_logloss: 0.638725\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.757576\tvalid_0's binary_logloss: 0.585509\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.717893\tvalid_0's binary_logloss: 0.610117\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.776335\tvalid_0's binary_logloss: 0.567231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.625186\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.637085\tvalid_0's binary_logloss: 0.656188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.655053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.561128\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.729076\tvalid_0's binary_logloss: 0.643127\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.634921\tvalid_0's binary_logloss: 0.645355\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.617759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.624824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.829726\tvalid_0's binary_logloss: 0.508022\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.482684\tvalid_0's binary_logloss: 0.688216\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.620023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.619669\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.644992\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.650072\tvalid_0's binary_logloss: 0.650335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.740981\tvalid_0's binary_logloss: 0.610619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.785714\tvalid_0's binary_logloss: 0.579343\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.666667\tvalid_0's binary_logloss: 0.653708\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.792929\tvalid_0's binary_logloss: 0.562008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.711039\tvalid_0's binary_logloss: 0.639218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.650392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.627291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.665224\tvalid_0's binary_logloss: 0.645931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.541486\tvalid_0's binary_logloss: 0.684282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.623377\tvalid_0's binary_logloss: 0.660494\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.618326\tvalid_0's binary_logloss: 0.664868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.778499\tvalid_0's binary_logloss: 0.553945\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.565296\tvalid_0's binary_logloss: 0.678854\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.628263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.663781\tvalid_0's binary_logloss: 0.657196\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.644271\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.80267\tvalid_0's binary_logloss: 0.636504\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.728716\tvalid_0's binary_logloss: 0.609346\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.65873\tvalid_0's binary_logloss: 0.65385\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.775613\tvalid_0's binary_logloss: 0.570894\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.650009\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.568541\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.647186\tvalid_0's binary_logloss: 0.667772\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.605454\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.762266\tvalid_0's binary_logloss: 0.634855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.782828\tvalid_0's binary_logloss: 0.58341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.709957\tvalid_0's binary_logloss: 0.625528\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.743867\tvalid_0's binary_logloss: 0.595369\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.744949\tvalid_0's binary_logloss: 0.678209\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.733766\tvalid_0's binary_logloss: 0.630524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.618464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.632447\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "3 features with a correlation magnitude greater than 0.50.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.722222\tvalid_0's binary_logloss: 0.61278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.787879\tvalid_0's binary_logloss: 0.56569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.652237\tvalid_0's binary_logloss: 0.658403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.700577\tvalid_0's binary_logloss: 0.630672\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.691198\tvalid_0's binary_logloss: 0.658427\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.677489\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.622591\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.775613\tvalid_0's binary_logloss: 0.571411\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.640693\tvalid_0's binary_logloss: 0.665947\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.582612\tvalid_0's binary_logloss: 0.677826\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.670274\tvalid_0's binary_logloss: 0.653915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.590164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.747114\tvalid_0's binary_logloss: 0.661943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.611342\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.672439\tvalid_0's binary_logloss: 0.659946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.611093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.622126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.685426\tvalid_0's binary_logloss: 0.629464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.621585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.765512\tvalid_0's binary_logloss: 0.573258\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.768398\tvalid_0's binary_logloss: 0.562796\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.739538\tvalid_0's binary_logloss: 0.630232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.649624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.656193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.718615\tvalid_0's binary_logloss: 0.607823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.646562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.620309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.580808\tvalid_0's binary_logloss: 0.677185\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.595364\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.659452\tvalid_0's binary_logloss: 0.647795\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.829365\tvalid_0's binary_logloss: 0.642796\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.573007\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.641352\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.650794\tvalid_0's binary_logloss: 0.646813\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.791486\tvalid_0's binary_logloss: 0.612106\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's auc: 0.698413\tvalid_0's binary_logloss: 0.633699\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.7114\tvalid_0's binary_logloss: 0.61295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.611111\tvalid_0's binary_logloss: 0.665412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.642136\tvalid_0's binary_logloss: 0.652053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.627761\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.708514\tvalid_0's binary_logloss: 0.605064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.474387\tvalid_0's binary_logloss: 0.686507\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.614719\tvalid_0's binary_logloss: 0.671265\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.591631\tvalid_0's binary_logloss: 0.679249\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.592542\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.652597\tvalid_0's binary_logloss: 0.678631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.744589\tvalid_0's binary_logloss: 0.635985\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.570371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.753247\tvalid_0's binary_logloss: 0.666527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.652958\tvalid_0's binary_logloss: 0.67423\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.663059\tvalid_0's binary_logloss: 0.644066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.665224\tvalid_0's binary_logloss: 0.654258\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.689755\tvalid_0's binary_logloss: 0.632502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.700577\tvalid_0's binary_logloss: 0.661527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.611497\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.618136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.76912\tvalid_0's binary_logloss: 0.567585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.634087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.55772\tvalid_0's binary_logloss: 0.67504\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's auc: 0.81241\tvalid_0's binary_logloss: 0.553104\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.636213\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.676046\tvalid_0's binary_logloss: 0.629683\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.633478\tvalid_0's binary_logloss: 0.661296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.596041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.670996\tvalid_0's binary_logloss: 0.640235\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.516955\tvalid_0's binary_logloss: 0.686506\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.63293\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.613069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's auc: 0.784271\tvalid_0's binary_logloss: 0.55953\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.497475\tvalid_0's binary_logloss: 0.686665\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "2 features with a correlation magnitude greater than 0.55.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.609703\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.727994\tvalid_0's binary_logloss: 0.626604\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.627345\tvalid_0's binary_logloss: 0.673331\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.673882\tvalid_0's binary_logloss: 0.634022\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.668412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.730159\tvalid_0's binary_logloss: 0.609324\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.635642\tvalid_0's binary_logloss: 0.666821\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.648629\tvalid_0's binary_logloss: 0.65992\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.633478\tvalid_0's binary_logloss: 0.677341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.626623\tvalid_0's binary_logloss: 0.667108\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.81241\tvalid_0's binary_logloss: 0.541965\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.633657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.645022\tvalid_0's binary_logloss: 0.651843\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.574759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.629149\tvalid_0's binary_logloss: 0.665768\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.782107\tvalid_0's binary_logloss: 0.573292\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.622655\tvalid_0's binary_logloss: 0.654125\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.710678\tvalid_0's binary_logloss: 0.625868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.532107\tvalid_0's binary_logloss: 0.685275\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.600462\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.674603\tvalid_0's binary_logloss: 0.676834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.655483\tvalid_0's binary_logloss: 0.649571\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.596984\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.731602\tvalid_0's binary_logloss: 0.611538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.607084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.68254\tvalid_0's binary_logloss: 0.642828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.666568\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.65265\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.686147\tvalid_0's binary_logloss: 0.639432\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.595496\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.562183\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.685426\tvalid_0's binary_logloss: 0.644367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.74531\tvalid_0's binary_logloss: 0.609969\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.598262\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.695527\tvalid_0's binary_logloss: 0.618516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.61544\tvalid_0's binary_logloss: 0.661595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.61813\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.569757\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.620877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's auc: 0.834055\tvalid_0's binary_logloss: 0.525319\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.611115\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.784271\tvalid_0's binary_logloss: 0.558648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.629149\tvalid_0's binary_logloss: 0.659466\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.577201\tvalid_0's binary_logloss: 0.671588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.64046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.645022\tvalid_0's binary_logloss: 0.651116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.647908\tvalid_0's binary_logloss: 0.649281\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.646465\tvalid_0's binary_logloss: 0.66663\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.623016\tvalid_0's binary_logloss: 0.671762\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.735931\tvalid_0's binary_logloss: 0.609872\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's auc: 0.821789\tvalid_0's binary_logloss: 0.502617\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.7886\tvalid_0's binary_logloss: 0.564562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.665945\tvalid_0's binary_logloss: 0.651595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.644\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.657287\tvalid_0's binary_logloss: 0.637779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.672799\tvalid_0's binary_logloss: 0.678829\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.555916\tvalid_0's binary_logloss: 0.681317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.604055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.7886\tvalid_0's binary_logloss: 0.567857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's auc: 0.793651\tvalid_0's binary_logloss: 0.56\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's auc: 0.751804\tvalid_0's binary_logloss: 0.605608\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.707071\tvalid_0's binary_logloss: 0.63801\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.628431\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.792208\tvalid_0's binary_logloss: 0.54705\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.579718\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.797258\tvalid_0's binary_logloss: 0.538277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.623731\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.78355\tvalid_0's binary_logloss: 0.575486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.75938\tvalid_0's binary_logloss: 0.662486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.651494\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.60.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.699856\tvalid_0's binary_logloss: 0.621399\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.683261\tvalid_0's binary_logloss: 0.644753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.607776\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's auc: 0.833333\tvalid_0's binary_logloss: 0.496494\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.667388\tvalid_0's binary_logloss: 0.638485\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.649472\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.419913\tvalid_0's binary_logloss: 0.689397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.59127\tvalid_0's binary_logloss: 0.669072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.825397\tvalid_0's binary_logloss: 0.561358\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.703463\tvalid_0's binary_logloss: 0.67736\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.705988\tvalid_0's binary_logloss: 0.653187\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.507937\tvalid_0's binary_logloss: 0.686702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.741703\tvalid_0's binary_logloss: 0.600863\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.678211\tvalid_0's binary_logloss: 0.642794\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.609268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's auc: 0.798701\tvalid_0's binary_logloss: 0.55102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.629149\tvalid_0's binary_logloss: 0.659946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.700577\tvalid_0's binary_logloss: 0.623412\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.603041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.799423\tvalid_0's binary_logloss: 0.549671\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "12 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 12 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.656015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.611111\tvalid_0's binary_logloss: 0.682817\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.731241\tvalid_0's binary_logloss: 0.650321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.640739\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.691198\tvalid_0's binary_logloss: 0.646735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.756854\tvalid_0's binary_logloss: 0.584857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.515873\tvalid_0's binary_logloss: 0.685652\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.735209\tvalid_0's binary_logloss: 0.620855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.704906\tvalid_0's binary_logloss: 0.618142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.633292\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.696248\tvalid_0's binary_logloss: 0.662662\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.559524\tvalid_0's binary_logloss: 0.683482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.614229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.646371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.801227\tvalid_0's binary_logloss: 0.657253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.65368\tvalid_0's binary_logloss: 0.651723\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's auc: 0.68759\tvalid_0's binary_logloss: 0.642742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.712843\tvalid_0's binary_logloss: 0.654141\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.603363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.620757\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.580874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.62987\tvalid_0's binary_logloss: 0.652233\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.637445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.721501\tvalid_0's binary_logloss: 0.615763\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.736652\tvalid_0's binary_logloss: 0.606187\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.63182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.61544\tvalid_0's binary_logloss: 0.673288\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.639726\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.715729\tvalid_0's binary_logloss: 0.62951\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's auc: 0.789322\tvalid_0's binary_logloss: 0.578672\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.761183\tvalid_0's binary_logloss: 0.569096\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.691919\tvalid_0's binary_logloss: 0.677313\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.647744\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.767677\tvalid_0's binary_logloss: 0.607868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.625541\tvalid_0's binary_logloss: 0.656331\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.709957\tvalid_0's binary_logloss: 0.625432\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.78355\tvalid_0's binary_logloss: 0.573986\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.751082\tvalid_0's binary_logloss: 0.610319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.623377\tvalid_0's binary_logloss: 0.659815\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.727273\tvalid_0's binary_logloss: 0.598356\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "14 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "6 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "7 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 7 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.743146\tvalid_0's binary_logloss: 0.606126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's auc: 0.770563\tvalid_0's binary_logloss: 0.575865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.615895\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.580808\tvalid_0's binary_logloss: 0.679801\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.69228\tvalid_0's binary_logloss: 0.676813\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.701299\tvalid_0's binary_logloss: 0.631326\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.606782\tvalid_0's binary_logloss: 0.676429\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.734488\tvalid_0's binary_logloss: 0.614024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.750361\tvalid_0's binary_logloss: 0.623939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.639182\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.65.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.639165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.72583\tvalid_0's binary_logloss: 0.621289\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.844156\tvalid_0's binary_logloss: 0.514866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.665945\tvalid_0's binary_logloss: 0.652803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.624122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.725469\tvalid_0's binary_logloss: 0.666479\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.732323\tvalid_0's binary_logloss: 0.645272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.656566\tvalid_0's binary_logloss: 0.676511\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.695166\tvalid_0's binary_logloss: 0.64416\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.686508\tvalid_0's binary_logloss: 0.65266\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "17 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "3 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "4 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 4 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.62269\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.712121\tvalid_0's binary_logloss: 0.632456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.738817\tvalid_0's binary_logloss: 0.602292\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.771645\tvalid_0's binary_logloss: 0.67581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.720058\tvalid_0's binary_logloss: 0.615129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.62482\tvalid_0's binary_logloss: 0.674153\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.733045\tvalid_0's binary_logloss: 0.61676\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.689033\tvalid_0's binary_logloss: 0.64514\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.640693\tvalid_0's binary_logloss: 0.661316\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.738095\tvalid_0's binary_logloss: 0.592126\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "9 features required for cumulative importance of 0.65 after one hot encoding.\n",
      "11 features do not contribute to cumulative importance of 0.65.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.742424\tvalid_0's binary_logloss: 0.597483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.657287\tvalid_0's binary_logloss: 0.664599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.858586\tvalid_0's binary_logloss: 0.604072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.697691\tvalid_0's binary_logloss: 0.619125\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.681457\tvalid_0's binary_logloss: 0.654717\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.681818\tvalid_0's binary_logloss: 0.636315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.627706\tvalid_0's binary_logloss: 0.675735\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.777778\tvalid_0's binary_logloss: 0.590485\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.677489\tvalid_0's binary_logloss: 0.643655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.613997\tvalid_0's binary_logloss: 0.661715\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "10 features required for cumulative importance of 0.70 after one hot encoding.\n",
      "10 features do not contribute to cumulative importance of 0.70.\n",
      "\n",
      "11 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 11 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.755411\tvalid_0's binary_logloss: 0.581206\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.726551\tvalid_0's binary_logloss: 0.621037\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's auc: 0.771284\tvalid_0's binary_logloss: 0.569505\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.694805\tvalid_0's binary_logloss: 0.633353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.695887\tvalid_0's binary_logloss: 0.669964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.784993\tvalid_0's binary_logloss: 0.618134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.537879\tvalid_0's binary_logloss: 0.684887\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.676768\tvalid_0's binary_logloss: 0.638881\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.631599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.780664\tvalid_0's binary_logloss: 0.603789\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "11 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "9 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "10 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 10 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.69697\tvalid_0's binary_logloss: 0.624366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.573232\tvalid_0's binary_logloss: 0.678839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.678932\tvalid_0's binary_logloss: 0.629716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.679654\tvalid_0's binary_logloss: 0.638734\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.759019\tvalid_0's binary_logloss: 0.658569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.752525\tvalid_0's binary_logloss: 0.607431\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.747475\tvalid_0's binary_logloss: 0.607429\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.613276\tvalid_0's binary_logloss: 0.675229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.670274\tvalid_0's binary_logloss: 0.655875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.702742\tvalid_0's binary_logloss: 0.608065\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.80 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.80.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.681097\tvalid_0's binary_logloss: 0.64427\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.650794\tvalid_0's binary_logloss: 0.661444\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.678211\tvalid_0's binary_logloss: 0.631347\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.75974\tvalid_0's binary_logloss: 0.581802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.661463\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.643218\tvalid_0's binary_logloss: 0.653153\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.795815\tvalid_0's binary_logloss: 0.622496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.867244\tvalid_0's binary_logloss: 0.506447\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.627706\tvalid_0's binary_logloss: 0.671008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.587662\tvalid_0's binary_logloss: 0.67484\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "13 features required for cumulative importance of 0.85 after one hot encoding.\n",
      "7 features do not contribute to cumulative importance of 0.85.\n",
      "\n",
      "8 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 8 features.\n",
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.621212\tvalid_0's binary_logloss: 0.668655\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.704185\tvalid_0's binary_logloss: 0.669687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.506133\tvalid_0's binary_logloss: 0.686159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.675325\tvalid_0's binary_logloss: 0.643173\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.706349\tvalid_0's binary_logloss: 0.676629\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.73088\tvalid_0's binary_logloss: 0.65812\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.713564\tvalid_0's binary_logloss: 0.612407\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.720779\tvalid_0's binary_logloss: 0.613866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.555407\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.626263\tvalid_0's binary_logloss: 0.673915\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "15 features required for cumulative importance of 0.90 after one hot encoding.\n",
      "5 features do not contribute to cumulative importance of 0.90.\n",
      "\n",
      "6 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 6 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.45 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.576479\tvalid_0's binary_logloss: 0.675798\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.790043\tvalid_0's binary_logloss: 0.583154\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.684704\tvalid_0's binary_logloss: 0.628785\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.707792\tvalid_0's binary_logloss: 0.623362\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.781385\tvalid_0's binary_logloss: 0.570993\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.660173\tvalid_0's binary_logloss: 0.641839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.642496\tvalid_0's binary_logloss: 0.662042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.559524\tvalid_0's binary_logloss: 0.680196\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.693362\tvalid_0's binary_logloss: 0.629681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.719336\tvalid_0's binary_logloss: 0.624502\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "16 features required for cumulative importance of 0.95 after one hot encoding.\n",
      "4 features do not contribute to cumulative importance of 0.95.\n",
      "\n",
      "5 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 5 features.\n"
     ]
    }
   ],
   "source": [
    "#the following for with search for the best score based on a svm classifier\n",
    "#and with the best score, it will find the best parameters to do feature selection\n",
    "score = 0.0000000\n",
    "for idx,x in enumerate(parameters_features['missing_threshold']):\n",
    "    for idy,y in enumerate(parameters_features['correlation_threshold']):\n",
    "        for idz,z in enumerate(parameters_features['cumulative_importance']):\n",
    "            fs.identify_all(selection_params = {'missing_threshold': parameters_features['missing_threshold'][idx], \n",
    "                                                'correlation_threshold': parameters_features['correlation_threshold'][idy], \n",
    "                                                'task': 'classification', 'eval_metric': 'auc', \n",
    "                                                 'cumulative_importance': parameters_features['cumulative_importance'][idz]})\n",
    "            train_removed_all_once = fs.remove(methods = 'all', keep_one_hot = True)\n",
    "            \n",
    "            data_features= train_removed_all_once.to_numpy()\n",
    "            \n",
    "            imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "            data_features = imputer.fit_transform(data_features)\n",
    "            data_feat = pd.DataFrame(data_features, index=range(data_features.shape[0]),\n",
    "                                      columns=range(data_features.shape[1]))\n",
    "\n",
    "            #Lets first normalize the features for K-NN and SVM\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(data_feat)\n",
    "            data_feat = scaler.transform(data_feat)\n",
    "\n",
    "            #Splitting of data to see model accuracy after cross validation and gridsearch\n",
    "            data_feat_train, data_feat_test, data_class_train, data_class_test = train_test_split(data_feat,data_class,test_size=0.25,stratify=data_class,random_state=1234)\n",
    "            \n",
    "            clf_svm = svm.SVC()\n",
    "            param_grid = {'C': np.logspace(-1, 3, 9),  \n",
    "                          'gamma': np.logspace(-7, -0, 8)}\n",
    "\n",
    "            svm_gridsearch = GridSearchCV(clf_svm,param_grid,n_jobs=-1, cv = 10)\n",
    "            svm_gridsearch.fit(data_feat_train,data_class_train)\n",
    "            if svm_gridsearch.best_score_ >= score:\n",
    "                score = svm_gridsearch.best_score_\n",
    "                parameters_values = [parameters_features['missing_threshold'][idx],parameters_features['correlation_threshold'][idy],parameters_features['cumulative_importance'][idz]]\n",
    "            #print(\"Best parameters: \" + str(svm_gridsearch.best_params_))\n",
    "            #print(\"Best score : \" + str(svm_gridsearch.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738122332859175\n",
      "[0.39999999999999997, 0.7, 0.7500000000000001]\n"
     ]
    }
   ],
   "source": [
    "#\"0.7356330014224751{'C': 3.1622776601683795, 'gamma': 0.1}\"\n",
    "print(score)\n",
    "print(parameters_values)\n",
    "#[0.39999999999999997, 0.7, 0.7500000000000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 features with greater than 0.40 missing values.\n",
      "\n",
      "0 features with a single unique value.\n",
      "\n",
      "1 features with a correlation magnitude greater than 0.70.\n",
      "\n",
      "Training Gradient Boosting Model\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.70202\tvalid_0's binary_logloss: 0.636678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.722944\tvalid_0's binary_logloss: 0.617109\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.723665\tvalid_0's binary_logloss: 0.614158\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.345599\tvalid_0's binary_logloss: 0.692999\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's auc: 0.779221\tvalid_0's binary_logloss: 0.564797\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.736291\tvalid_0's binary_logloss: 0.634143\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.690476\tvalid_0's binary_logloss: 0.636135\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.74026\tvalid_0's binary_logloss: 0.600417\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.624673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.752525\tvalid_0's binary_logloss: 0.578294\n",
      "\n",
      "0 features with zero importance after one-hot encoding.\n",
      "\n",
      "12 features required for cumulative importance of 0.75 after one hot encoding.\n",
      "8 features do not contribute to cumulative importance of 0.75.\n",
      "\n",
      "9 total features out of 20 identified for removal after one-hot encoding.\n",
      "\n",
      "['missing', 'single_unique', 'collinear', 'zero_importance', 'low_importance'] methods have been run\n",
      "\n",
      "Removed 9 features.\n",
      "      F3    F4    F6    F7   F9  F10   F13  F14   F16   F19   F20\n",
      "0     16  2.02 -2.35 -1.98   85    6  1.08   15 -3.49  15.3   NaN\n",
      "1     86 -0.90  0.14  0.83  107    1  1.06   -8  0.34  10.1   NaN\n",
      "2    165  0.73  0.10  2.57   41    5  0.42   -6 -0.62  11.0  1.55\n",
      "3    191 -1.50  0.33  1.24   17    2  1.74   15  0.63   6.3  0.95\n",
      "4     13  0.25 -0.90  2.67   12    8  1.25   25 -2.41  10.5   NaN\n",
      "..   ...   ...   ...   ...  ...  ...   ...  ...   ...   ...   ...\n",
      "495  138  1.36  1.05  4.00   36   16  0.70   23 -1.24  20.9  2.87\n",
      "496  102  2.06  0.84  3.63   57   -2  0.56   -6 -1.29  19.6  1.83\n",
      "497  211  0.18  0.30  1.22   47  -49  0.78    7 -0.45   5.9 -1.03\n",
      "498   94 -0.86  0.66  1.25   23    5  0.11   -8  1.58   6.4   NaN\n",
      "499  104  0.23 -1.41  3.46   31  -19  1.84  -13 -1.56  18.3  3.65\n",
      "\n",
      "[500 rows x 11 columns]\n",
      "Best parameters: {'C': 100.0, 'gamma': 0.01}\n",
      "Best score : 0.7169274537695591\n",
      "Average accuracy: 0.7169274537695591\n",
      "[[54 16]\n",
      " [16 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.77      0.77        70\n",
      "        True       0.71      0.71      0.71        55\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.74      0.74      0.74       125\n",
      "weighted avg       0.74      0.74      0.74       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = FeatureSelector(data = data_full, labels = data_class)\n",
    "fs.identify_all(selection_params = {'missing_threshold': 0.39999999999999997,    \n",
    "                                    'correlation_threshold': 0.7, \n",
    "                                    'task': 'classification',    \n",
    "                                    'eval_metric': 'auc', \n",
    "                                    'cumulative_importance': 0.7500000000000001})\n",
    "\n",
    "\n",
    "train_removed_all_once = fs.remove(methods = 'all', keep_one_hot = True)\n",
    "print(train_removed_all_once)           \n",
    "data_features= train_removed_all_once.to_numpy()\n",
    "          \n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "data_features = imputer.fit_transform(data_features)\n",
    "data_feat = pd.DataFrame(data_features, index=range(data_features.shape[0]),\n",
    "                                      columns=range(data_features.shape[1])) \n",
    "#Lets first normalize the features for K-NN and SVM\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_feat)\n",
    "data_feat = scaler.transform(data_feat)\n",
    "\n",
    "#Splitting of data to see model accuracy after cross validation and gridsearch\n",
    "data_feat_train, data_feat_test, data_class_train, data_class_test = train_test_split(data_feat,data_class,test_size=0.25,stratify=data_class,random_state=1234)\n",
    "            \n",
    "clf_svm = svm.SVC()\n",
    "param_grid = {'C': np.logspace(-1, 3, 9),  \n",
    "              'gamma': np.logspace(-7, -0, 8)}\n",
    "\n",
    "svm_gridsearch = GridSearchCV(clf_svm,param_grid,n_jobs=-1, cv = 10)\n",
    "svm_gridsearch.fit(data_feat_train,data_class_train)\n",
    "print(\"Best parameters: \" + str(svm_gridsearch.best_params_))\n",
    "print(\"Best score : \" + str(svm_gridsearch.best_score_))\n",
    "#Now lets used cross validation in the whole data set, but with the best parameters by gridsearch\n",
    "svm_model = svm.SVC(C = svm_gridsearch.best_params_['C'],gamma=svm_gridsearch.best_params_['gamma'])\n",
    "\n",
    "#Now lets used cross validation in the whole data set, but with the best parameters by gridsearch\n",
    "score_svm = cross_val_score(svm_model,data_feat_train,data_class_train,cv=10,n_jobs=-1)\n",
    "print('Average accuracy:', np.mean(score_svm))\n",
    "\n",
    "#Now lets compute the confussion matrix by splitting the data into trainning and testing\n",
    "svm_model.fit(data_feat_train,data_class_train)\n",
    "svm_pred = svm_model.predict(data_feat_test)\n",
    "print(confusion_matrix(data_class_test, svm_pred))\n",
    "print(classification_report(data_class_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 14}\n",
      "Best score: 0.6561877667140825\n"
     ]
    }
   ],
   "source": [
    "knn_gridcv = KNeighborsClassifier()\n",
    "#create a dictionary with the number of neighbors to try\n",
    "param_gridsearch = {'n_neighbors': np.arange(1,80)}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(knn_gridcv,param_gridsearch,cv=10)\n",
    "knn_gridsearch.fit(data_feat_train,data_class_train)\n",
    "print(\"Best parameters: \" + str(knn_gridsearch.best_params_))\n",
    "print(\"Best score: \"+ str(knn_gridsearch.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6561877667140825\n",
      "[[61  9]\n",
      " [33 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.87      0.74        70\n",
      "        True       0.71      0.40      0.51        55\n",
      "\n",
      "    accuracy                           0.66       125\n",
      "   macro avg       0.68      0.64      0.63       125\n",
      "weighted avg       0.68      0.66      0.64       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now lets used cross validation in the whole data set, but with the best parameters by gridsearch\n",
    "knn_model = KNeighborsClassifier(n_neighbors = knn_gridsearch.best_params_['n_neighbors'])\n",
    "\n",
    "#Now lets used cross validation in the whole data set, but with the best parameters by gridsearch\n",
    "score_knn = cross_val_score(knn_model,data_feat_train,data_class_train,cv=10,n_jobs=-1)\n",
    "print('Average accuracy:', np.mean(score_knn))\n",
    "\n",
    "#Now lets compute the confussion matrix by splitting the data into trainning and testing\n",
    "knn_model.fit(data_feat_train,data_class_train)\n",
    "knn_pred = knn_model.predict(data_feat_test)\n",
    "print(confusion_matrix(data_class_test, knn_pred))\n",
    "print(classification_report(data_class_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 18}\n",
      "Best score: 0.6104551920341394\n"
     ]
    }
   ],
   "source": [
    "#Decision tree using grid search\n",
    "clf_tree = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "param_grid = {'max_depth': np.arange(4,21),'min_samples_split': np.arange(4,21),'min_samples_leaf': np.arange(4,21)}\n",
    "tree_gridcv = GridSearchCV(clf_tree,param_grid,cv=10 ,n_jobs=-1)\n",
    "tree_gridcv.fit(data_feat_train,data_class_train)\n",
    "\n",
    "print(\"Best parameters: \" + str(tree_gridcv.best_params_))\n",
    "print(\"Best score: \" + str(tree_gridcv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6104551920341394\n",
      "[[36 34]\n",
      " [34 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.51      0.51        70\n",
      "        True       0.38      0.38      0.38        55\n",
      "\n",
      "    accuracy                           0.46       125\n",
      "   macro avg       0.45      0.45      0.45       125\n",
      "weighted avg       0.46      0.46      0.46       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now with these parameters, lets perform cross validation\n",
    "clf_tree_prunned = tree.DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                               max_depth= tree_gridcv.best_params_['max_depth'],\n",
    "                                               min_samples_leaf= tree_gridcv.best_params_['min_samples_leaf'],\n",
    "                                               min_samples_split=tree_gridcv.best_params_['min_samples_split'] )\n",
    "\n",
    "#Now lets used cross validation in the whole data set, but with the best parameters by gridsearch\n",
    "score_tree = cross_val_score(clf_tree_prunned,data_feat_train,data_class_train,cv=10,n_jobs=-1)\n",
    "print('Average accuracy:', np.mean(score_tree))\n",
    "\n",
    "#Now lets compute the confussion matrix by splitting the data into trainning and testing\n",
    "clf_tree_prunned.fit(data_feat_train,data_class_train)\n",
    "tree_pred = clf_tree_prunned.predict(data_feat_test)\n",
    "print(confusion_matrix(data_class_test, tree_pred))\n",
    "print(classification_report(data_class_test, tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
